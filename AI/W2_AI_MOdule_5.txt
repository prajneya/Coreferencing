Hello friends, welcome to Module Five, Heuristic Search Methods in Artificial Intelligence studies of modules. We’ve already seen that it is possible to represent the problem using state space. We’ve already seen that there is possibility of using something called blind search methods like kit generate and test, breadth-first search, depth-first search to handle the search problem. But the problem with these methods that is, is going to enter into entangled into something called combinatorial explosion. Combinatorial explosion is number of options that you have. In the previous module, we have seen simple eight,five,three gallon water jug problem where we have only few nodes to explore and we could get the answer. But let us again pick up a problem like chess and it becomes impossible for us to get an answer. 

There are so many other problems which we can talk about where we can see that even a trivial problem like traveling salesman result into a serious combinatorial explosion. You cannot solve the problem in real time. And we have already seen that it is possible to learn from the domain which moves are better than others. And if you can somehow manage that it becomes easier for us to choose moves which are better and complete the search process in real time. So that’s precisely the theme of this particular module. Okay, so let us see what heuristic search methods have. Okay, let us begin with the introduction of something called heuristic function is a function which is applied to a state. 

Now, if you ask a chess player given a board position, two board positions which one is better, he would say this is better or that is better. Well, how better, how much there the quantitative representation then they’re not be able to view but here we’re thinking that way. We’re going to have a quantitative representation of goodness of the state. We call it the heuristic function response or the answer. So what does that mean? I’m given a chess board position, I apply that heuristic function, that heuristic function will give you – give me a value between minus ten and ten. Minus ten is a defeat from me, ten is a win for me and the value between minus ten to ten indicates the merit of that particular state, how good or bad that state is. 


So you can see. It is about using domain knowledge, okay. What the heuristic function take as an input? The problem state. And what it comes out with is the value, okay, how good or bad but ten, minus ten to ten in conventional way but you can design your own way. There is no standard as such. And here Farmer Fox Chicken Grain problem. Suppose if I design a heuristic function for Farmer Fox Chicken Grain problem for this assume that there is a function exist. It says everybody is on the left hand side, nothing, nobody is on the left hand side, everybody is on the right hand side. And what does that mean? That means that it is ten, it is win for us, the problem is solved, okay. In missionary cannibal case sorry it’s milk jug problem sorry it’s zero, zero, zero minus ten. 


What does that mean? If I have nothing left in all jugs then something terribly wrong. Minus ten, I’ll not [Indiscernible] [00:03:33] solution after this, okay. So is it kind of a dead end or loss, okay, a failure. So these are examples. But a more important thing is I must have some clear means of telling which move is better. For example, we have assumed that eight, zero, zero is the beginning this thing a move, okay. For example, I’m at a typical place in eight, zero – eight, five, three gallon water jug problem. I have few moves possible. I can move to eight, zero, zero. I can move to six, zero, two. I can move to three, five, zero and I can move to three, two, three, okay. 


And suppose if my heuristic function says that eight, zero, zero’s heuristic value is minus five, eight, six, zero, two is five. Three, five, zero is three and three, two, three is four. Now, it clearly indicates that six, zero, two is better than others. So what should I choose? I just choose six, zero, two, okay. So this is how I can apply heuristic function and get the move that I should choose rather than exploring all of them like breadth-first or exploring one branch and then the second branch and the third branch like DFS. I’m not doing it blindly and that’s why this is called guided search and not blind search or unguided search. Anyway, there are two problems. And there is two questions that you’d probably ask before we proceed further. 


First, how to write this function? Important one. Second, if this function, suppose if you know how to write this for them, how you put this function to use. In fact, the second answer is easy to – the second question is easy to answer. If I have this function I can just apply to a state and get that value and get that value between minus ten and ten and I’ll look at all possible alternatives. Suppose, if I’m here and I have five different moves from this I’ll apply this function to all of them. The side which one gives me the better heuristic value and we’ll choose that, that’s simple and okay. But that’s not that simple, we’ll see how, how, how to proceed using that. But that is precisely what we’re supposed to do and that’s the theme of this chapter. 


The first part how to write this function actually depends on the domain. And that’s the reason why we’re not going to discuss much about this. But if you know how to and there are some books available on how to write heuristic function for a given domain like chess. So we can choose the book that suits your domain, look for heuristic function or try writing for yourself but otherwise it’s simple. If you know how to write heuristic function whatever we’re going to talk about is perfectly all right. Even if you don’t know it’s still. Okay, we’ll look at the first method and that method is again pretty simple. What I do is I’m here in this state, I just apply one rule that is possible to be applied in this generate the node. If this node is better than this I’ll just go, that’s called hill climbing. Why it’s called hill climbing? I’m actually incrementing the heuristic value. 


If my current node’s heuristic value is three, I get a node with heuristic value five I just move. And then from five I get seven, I move, a seven, eight I can move up and so on. What my requirement is to reach to ten. I’ve already told you ten is the solution, okay, so that’s why it’s called hill climbing. So the algorithm is shown on the screen, pick up the start and make it current node, okay, so it’s simple. Pick up the start node, it’s the current node if it’s the goal, great, you don’t need to do anything. It is not fine, go further. Look at all possible rules to be applied. Apply the first rule, if it is better go to that node, okay. Generate new state by applying next rule, no rule is left. If you don’t have from this particular state there are no rules possible you can’t go further is a dead end. Say, you cannot move. 


Okay. Apply heuristic function, see which one is better. If it is better go ahead. Now you can see this example. This figure actually talks about. We’d begin with a state with heuristic value minus three. We apply for a stool, we get minus five. Can we move? We cannot because this particular node has lesser heuristic value. We’d like to have a better heuristic value so we’ll not move further. Next one is minus four. This also is not very good, okay. This is not better than the current one so we’ll not move. Zero is better than minus three so we’ll pick up that. Now the first node that we generate is minus one, which is obviously not as good. 


But the other one when you apply the second rule, the state that we get has value two so we move to two. Then we apply the first rule which makes it four so this state is good so we move to four. Then we have two options. One is four, which is same so we’ll not go for that. Next one is ten. Okay, so what we do now. We’ll jump to ten and we got a solution, okay. This is called hill climbing. Sounds simple, it is. But then there is a problem. Look at this typical case. We’d start with minus three. The first node is minus five, not very good. We have zero this is better so we move there then minus one not good, two, better, go there, four, we’re moving along quite nice, okay, four. But then there is a problem. 


There are two children neither of them has better value and we’re stuck. We’re stuck, we cannot move forward and we’re not at the solution. Remember when we’re at the solution when we get value ten. We don’t have the value ten. We get three and two. So none of them is a solution but we cannot go. So that is the problem with hill climbing that’s called local maxima. Why it’s called local? Because we’re not reached to the final goal state that’s a local surrounding, okay. And maximum is it is three and two are lesser value. So what you’re doing? You’re actually you start with minus three then zero then two then four. You’d reach to four. But then you can’t move further. It is actually mini maxima, it’s kind of a hill, okay. You reached to four you can’t move further, okay that is called local maxima, okay. There is something called dead end also. 
	

You can look at this example. Same three, zero, two, four, four and six. Now you choose six but then there are no rules possible in this case. It is very good rule six, if it’s not solution but then there are no possible rules to be applied. When there are no possibility of applying any rules we can’t move further. So six is a dead end in this case. Okay, there is something called steepest ascent hill climbing which is a little different than the hill climbing, okay. What does it do? Instead of picking up one rule and find out if the node is better, what it does it explores everyone and pick up the best one. You see the example, minus five, four and zero for three. So you pick up four, again, pick up all children are four, five, six and four. We pick up six which is best, okay, this is what we’re doing. We’re picking up the best child. And then eight and then ten, okay. 


So this is what is known as steepest ascent hill climbing. Why it is called steepest ascent because we’re looking at all possible nodes and we’ll pick up the node which gives us steepest ascent, will give us highest value of the heuristic value of the children, okay. So we’ll choose the child with highest heuristic value that’s why it’s called steepest ascent. Okay, the next search method that we’re going to use, we’re going to talk about is called best first search. Now this is little different than hill climbing, a little better than hill climbing in some sense. We’ve seen that we entangled into local maxima. If we find that on a children don’t have the value better than us, what should we do? Hill climbing stops there, right. It fails there and in case of best first search we don’t do it. In fact, it allows you to pick up the best child, not only that irrespective of the parents value. And like the previous case we have four which has two and three and you cannot go because it’s worst. In case of best first, you can even pick up three. 


Not only that, you can even go ahead and pick up some other brands, some other node which is better than three, you can do it. Okay, so that is what best first search is. In fact, best first search you have three different types of nodes. First, which are already explored. Second, which are yet to be explored and the third which we’re considering right now, okay. The candidates for that thing so they’re best actually and so we’re always looking at best nodes. So that there are three one is listed on the slide, okay. So what we have is this. Pick up the start node and make it current, okay, the start node and take up all nodes, pick and store them in the heuristic sorted order of heuristic value. So what we have the best node on the top. Now we’re not looking at the children. 


We’re looking at just all nodes, okay. We explore the top when we get all nodes, we apply heuristic values to them, add them in the array and again pick up that node from the top. All explored nodes are kept in the other area. You maybe surprised. If we’re only picking up unexplored node what’s the point in storing explored nodes, quite interesting. Obviously they’re needed. Whenever you explore a node, whenever you generate children for a node what if the child is already explored. We’ve seen the earlier cases, the repeated nodes and the nodes which are already explored. So if you look at that array you can easily understand the children that you’re generating is already explored. So you don’t add them in the explored array and that’s why the reason we’re keeping that array, okay. 


So this is how we’re doing, okay. So the beginning you just insert all nodes in an array and other unexplored node in the other array and find out the best node from the array. If the array is empty they report failure. When the array becomes empty because there is no node to explore, okay. It is impossible in some cases but it is possible in some cases as well. So whenever there is no node to explore you cannot go further and there is no end, there is no this thing road ahead. Now two important characteristics of best first search. Best first, remember the word best first means that we’re only exploring best nodes, okay. So obviously we need to have unexplored nodes. I’ve already talked about the need. The other one which is also quite interesting is that we always pick up the best node irrespective of the parent value.


So unlike hill climbing it does not get stuck. It tries all possible way to explore the search surface and get the solution. Okay, the heuristic search process. If you look at the search process that is described earlier you move in this direction and this direction and this direction you may feel that it’s called jittery. It moves to and fro and it’s not going directly to the solution. But that is quite acceptable. Why? Because if there is – if you have a formula which can directly lead to a solution then it’s not an AI problem. There is a formula you just apply if the heuristic function gives you exact measure of how far the goal node is you don’t need to do. There is no search. The heuristic function exactly tells you the value, okay. 


In most cases, heuristic function will not give you exact value. It just gives you an estimate, okay and there are some mathematical ways of judging how estimate is near to the correct value and so and so forth. But eventually what we get when we use heuristic is the estimate of how far we are from the goal node. And when we only have an estimate it is likely that we try in one direction, we may fail, we have to try in the other direction and so and so forth. So it has to be that way. Okay and I’ve already talked about the chess playing programs use serious heuristics and sometimes the chess playing programs use heuristics based on the opponent. For example, Garry Kasparov, the Deep Blue machine which IBM built which has beaten Garry Kasparov three, two if you remember that was it was there in news for quite some time. 


So it could do it because the chess playing programs use heuristics based on the way the Garry Kasparov used to play chess. And you can see the best first search the next figure in the slide shows how best first search works. You have minus three, then minus five, minus two and three are the children. Now you can see that there is a node minus three, which is explored three, which is also explored now which is being explored right now. Minus five, two, minus one and two are yet to be explored. So they are part of the unexplored nodes. Minus three and two now they’re explored. Okay, we’re only taking a small segment of this thing. You can see that now two is the best this thing. So out of minus five, two, minus one and minus two, two is the best node. 


See, we’re not doing exploring it like hill climbing, okay. If we’re exploring like hill climbing we’ve come to a dead end actually because three only two children minus one and minus two both of them are having less value so we’ll not be going forward. But here in this case, two is the best node, so we’ll explore two. So if two is explored we get minus three, minus two and one. So we’ll explore one. Okay, this is again different than the hill climbing because if this where hill climbing one cannot be explored it has lesser value than two. So but we’re doing it, okay so we’re picking up, we’re taking that as correct and we’re going forward. So what we have? One, we have minus three and minus four. Now you can see in this particular case, minus three, two, one and three, all four of the nodes are explored. Minus one is the best node right now, okay. 


So we’re going to explore it and so and so forth. You can see that this search process is jittery obviously and I’ve told you the reason for it. And it is so you can see minus one you explored where one is three, other one is four. Okay, let us look at one important factor that was best first search. Okay, we have in fact you can go further and get the answer but best first search basically is the search where you use heuristic value and you just pick up the best node irrespective of what your children are and what the parent’s heuristic value is. Okay, so the branching factor, the next thing which we’re trying to explore. I’ve already told you, when you explore a search tree or a graph, the difference between search tree and a graph is, a graph will have, a child will have a point that is quite possible that will also point to a parent. 


A parent maybe a children, to a children and so and so forth. What is a branching factor? Branching factor is number of nodes that you’ll have as a child on an average. Okay, for a complete binary tree I’ve already talked about number of node is almost double themselves at every level. To the branching factor of thirty five chess is an example. At level number one you have thirty five. Level number two you have thirty five into thirty five I mean, thirty six in the earlier node. The next level is thirty five into thirty five into thirty five minus whatever you’ve explored so far. That many huge number of nodes. In fact, that’s the reason why my guess is what you’re supposed to do is to like for example, you’re exploring chess and after six levels you cannot explore seven, that is too much for you and you choose one node. 


Now that node maybe little bad that node may not be as good as it looks at the first shot. So what you do? You cannot explore the entire level further but you can explore that node further. When that particular node that you’re planning to choose is explored a little further it is called secondary search that is applied in chess and many other cases many times. But anyway this branching factor is an important point in the search process, okay. Now an important something little different which is little different than the conventional state space search that we’ve seen so far. It is possible to represent a problem in two different ways. In one way, we have already done like for example missionary cannibal problem you start from three, three, zero, zero then move along and at the end you get zero, zero, three, three. So that is how we do it like that is called constructive search. 


We start with an initial state and reach to the final state. But there is one more way. One more way is to like for example let us take the same missionary cannibal case. What we do is we just write some sequence of random states, okay and call that thing as node one. Another sequence node two, another sequence node three and so and so forth. Now what we do is we just check if the first sequence is a solution, second sequence is a solution, third sequence is a solution and so and so forth. Now in this state space what we do is every node represents a particular solution, a potential solution. Okay, a particular sequence which may be the right answer to this missionary cannibal problem. 


And what we do is we just apply kind of a generate and test. We just see if the sequence is a solution if not we’ll pick up some other sequence. If not we’ll pick up the third sequence and so and so forth. So that is called perturbation search, okay, unlike the constructive search that we have seen so far. Okay, solution search can be done in either way. The first case is one, the second case is one. For missionary cannibal reconstructive search method is a little better because it’s easier. Solution space are space, exploration is little complex. But for some other problems that is a better method we’ll see that thing in our eighth module when we look at genetic algorithms. Well, we see genetic algorithms are very good at those kind of problems where you have to apply perturbation search, okay. Both methods are used in factors. 


Now let us look at the summary of what we have looked at this module, in the heuristic search module. The heuristic search module, heuristic search method is a method, which is not blind like BFS, DFS and generate and test. The method is applied in a way that all alternative state is possible, all children of a node they are tested and checked if one is better than the other. And what you do is you pick up a better node. And how it is done? It is done by applying something called a heuristic function. A heuristic function is based on the domain knowledge, applying that heuristic function will tell you exactly how good or a bad that particular state is. Usually this value is between minus ten and ten so that value will give you the ranking of or the merit of every state that you have at your disposal and you can choose the best one. That’s the power of heuristic search method. There are few heuristic search methods that we’ve seen in this particular module. 


One of them is hill climbing. Hill climbing is about simple. You just explore your children, apply heuristic function and pick up, okay sorry, the simplest of hill climbing you don’t do that. The simplest of hill climbing you apply one of the rules and look at what you get and that node if that node has a better value you just move there. Not better value you generate the other children and so and so forth. The steepest ascent hill climbing, the little different version of it and you can generate all nodes and pick up the best and so on. The problem of hill climbing is that you end up in a local maxima. It is quite possible that you get children all of them having lesser value than the parent and you can’t move forward, that is steepest ascent that is the local maxima problem. 


The other method that we’ve seen is called best first search. Best first search is about exploring this but unlike hill climbing you can just pick up the best node. What you’ve to do is to just store all unexplored node irrespective of whether which branch of the tree you’re exploring and pick up the best node based on the heuristic value. So it is quite and this search process maybe quite jittery that moves across different branches and so and so forth. But it is justified because we’re looking at an AI problem. The heuristic value is just an estimate. Heuristic value is not an exact answer and that’s why it has to be that way. We’re also seeing it is – that it is possible to apply a little different type of a search called solution search where every node in this search space represents a solution. 


So what we’re doing is kind of a generate and test, we’ll just look at a sequence. And for example, we’ll take a missionary cannibal program problem. We’ll just look at a typical sequence of states and see if it is a valid state acceptable one if not then we’ll pick up the something else and so on, that’s called perturbation search. The earlier search methods that we’ve seen are called constructive search methods. And both of them are used in practice. Some case is one search method is better than some other cases, the other method is better. And in some cases, they’re applied in a hybrid way. We’ll end this module. Thanks. 

