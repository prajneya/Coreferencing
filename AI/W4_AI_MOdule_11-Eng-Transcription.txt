Welcome friends, let us talk about we… we in the previous module we looked at the back propagation, the prerequisites to back propagation. In this particular module we’ll be looking at the learning process in back propagation neural network and… and we’ll also be having some introduction to the other type of neural network which is also used in practice called Hopfield networks. Learning in back propagation network, we've already seen that how the HI and OJ are calculated. One upon one, plus E raised to minus sum, okay. Those XIs and WIs and all that they are they are multiplied and you get. So okay that… that's how it is done. That is the first thing that we've already seen, and we know that the output is a real value between zero and one.

The required value is either zero or one. Now that is the first thing. For example, I need an output unit second unit to be on and the rest of unit to be off and there are six output units I… the answer that I get is zero one zero zero zero zero. Okay, the second unit is one, The rest are zero. So that is what I want but I may because the output between zero and one I may get something like, zero point one instead of zero, the first unit. The second unit one instead of that I get point ninety-eight and second, third one and so on. So, I get other than zero as values of output. Now how that problem can be solved or rather how to handle that. That's the first thing that we’ll discus. The PowerPoint looks… you better look at the PowerPoint now. It says that the actual output that you get is point one, point zero one, point ninety-two, point twenty-five, point ninety-two, point eighty-seven when I actually want is zero zero zero zero one one. Now what you are supposed do is to find… find out the difference. Now what is the difference? Difference basically is the error. Okay, in the absolute form. And what I want is one and what I get is point five, the error is point five. Okay, so that's the absolute value of error. And there is something called tolerance level as well. Remember in… in we have seen that in a sigmoid function case? You can't have one … instead… unless you have the total to be equal to infinity, it is impossible for you to get one. So you’ll have to have the tolerance level for example, we have assumed tolerance level to be point nine. Okay, so what does that mean? 

If the difference between what is expected and what is outcome is less than point ten, we accept it as valid input. So that's the second point. Remember what we discussed about expected values, the values that we get between zero and one, the third one is the difference. And the fourth thing is the tolerance level. If the difference is less than the tolerance level accepted, that… that… that unit is not required to be learned further it is… it is said to be learned and the output unit errors are known as delta two, conventionally. Okay, the second layer weight. There are two layers of weight W one and W two, okay? Remember what we discussed about the inputs flow in this direction the errors flow back? First of all, the errors are available at output layer. So at output layer we… we look at what's the actual value. What's the expected value and what's the difference. So, the actual value is OJ and the expected value is YJ. Then the difference is YJ minus OJ. Okay? But this is an absolute value of error and we require to normalize it. So we multiply that by OJ into one minus OJ. Why I'm doing it? I cannot explain. But accept this so it is YJ minus OJ the absolute value of error then you multiply it by OJ into one minus OJ. Similarly error at HI or hidden unit is calculated in a similar fashion. So what does it do? Okay, we call it delta one, the error at HI. So, there is an error coming in from an output unit to this hidden unit. And a hidden unit contains errors coming from all output units, okay? So, basically, is the…it calculates that this way so this is the hidden unit this is an output unit. So it says that the error at this output unit multiplied by this weight. The next hidden unit okay …the… the error here and the multiplied by weight. The error here and multiplied by weight. So in this fashion it calculates and it is shown on the screen. The W two double one that W two  the second layer weight. one one. The hidden layer one to the output layer one and error at one that is propagated back, okay? Same way error at O two and it is W two one two, okay? So that… that… that's how it calculates w one three and so on. So, it calculates that way. So, that way you calculate the error rate the hidden layer. The next slide shows the formulae. So it’s sigma I equal to one to M, because there are total M output… the hidden units. So, W two one J multiplied by delta two J. Now, that is the error at the HI Ith hidden unit, okay? So, that is how it is shown.

Look at two values calculated. Delta one for the first hidden unit and delta one for it Ith unit. And you can see that it is H one into one minus H one or HI into one minus HI that is for normalizing the error, okay? The… the absolute value of error is normalized by multiplying this. And you can see that the summation is also the same. The hidden unit, the output units, the error here and weight error here and weight error here and weight, their multiplications and those multiplications are summed up. And when we are looking at this remember we had a problem of negative and positive misclassification. So, negative misclassification you will have to increase weights. Positive misclassification you’ll have to reduce weights and that is you have to calculate weights that way. Interestingly, OJ into one minus OJ or HJ into one minus HJ is always negative. Because, one of them is positive, the other one will become negative. Okay so that's always negative. So, that is one thing. So error, if you just add that thing, multiply that thing it negates everything. For example, YJ is more than OJ okay, YJ minus OJ is positive. When you multiply with OJ and one minus OJ, it becomes negative. Similarly, if it is negative, IJ is less than OJ, the multiplication the value becomes positive so error is high. And you can just add okay? So you don't need to process it further you'll just add that because the sign is taken care of okay. The W two one one error is based on H one and O one, W two one one, H one and O one W two one two is H one and O two and so on, okay? If you want to update this weight W two one one, okay? So that is here the output unit A W two IJ Jth output unit Ith hidden unit okay. So that is the weight between the W two IJ is a weight between Ith hidden unit and Jth output unit okay. So if you want to update that weight that depends on H one that is coming in the value that is coming in and the error that is coming from this side okay.  That is something that you will have to change. Okay? That is going to have an effect. So… so we have this multiplication HI into Delta two J Ith hidden unit Jth output unit. Remember this. they are not same. I and J are different.

See, if I want to update that weight the formula is shown on the screen delta that's the difference is known as delta W two IJ. So that is, HI into delta two J and that is also multiplied by a value called eta, that is, point thirty-five. People found that if you use this, it learns better okay? So, that people use the researchers use some times and many a  times it is kept in some other values also but usually it is between point three and point four. Similarly, W two IJ the new value of that weight obviously is the old weight plus this delta value, the change that we want plus that delta, okay? And people have also researchers have also found that by just simply adding this the network will definitely learn but will learn bit slowly. So you what you can do is in the initial run, you let the weight gets updated that way but later on you multiply that with a value called alpha, which is quite near to one point nine or something. So, when that is multiplied, the speed of learning improves. The same thing happens in W two IJ as well. The almost the similar set of calculations are made. You can look at the PPT or the handout to see that thing there's no difference almost, okay? The only issue is that the… the… the second layer of weights we call them W two IJ and the first layer we call W one IJ.

Some other authors have chosen some other mechanism, some of them use that suffix at the end. Some of them use that suffix in the beginning. But otherwise, basically it is the same. And that alpha, that value is something near to nine, is called the momentum factor. As I said, it improves the speed of learning, and that's why it is called momentum factor. Once these weight updates are applied, one epoch is said to be over. Now remember, let me recap what we have done. You find an error at the output unit YJ minus OJ. Normalize that by multiplying it by OJ and one minus OJ. So, you have found that for all output units find this errors once that is found you calculate errors at His. HI is basically a summation of collect… connection, okay? It is connected to all output units every, for every weight unit, you look at that. So, for this particular weight it is HI and OJ we have also calculated the error. The error is delta J. That is this error the Jth unit or the first output unit. The second output, third output unit and there is a weight, okay?  So you… you calculate this error at the… the output unit multiply with… with the weight okay, you get that error at HI and how you calculate the… the update the weights okay? You just say that this is the error and you calculate that and now error is to be added. Remember that the original value is negated. So you are just adding an error you are improving it you're improving the weights. So once you do that, your weight becomes more aligned with the input, okay? So, that is what we have seen? So… so that now we are going to look at that complete algorithm in single shot. These are the… these are the building blocks for that algorithm, okay? So, once you apply input, calculate weights, update all weights, you apply the next input and it is a huge thing. For example, we have fifty employees and every employed had images fifty into twenty, one thousand total inputs are provided for each output. You check whether the output is right or wrong and for every wrong output, you will have to update weights, okay? So, once the whole thing is done, one epoch is said to be over and when one epoch is said to over only the first phase of the problem is solved. The second phase you redo it. In fact, you require many, many epochs. In some cases you required to do twenty five thousand, thirty thousand epochs. This is a typical case of signature recognition system which some of my students worked at. It minimum requires twenty-five thousand to thirty thousand inputs and if the input is more complex number of input units are more, number of output units are more, you probably need huge number of iterations sometimes even going beyond one lakh or two lakh sometimes.

The only catch is that it sometimes you won't get it learning. So, after some reasonable period of time reasonable number of iterations, if you find that it is not learning.  There are two ways of finding it out. One, look at the difference between errors. So, if the weights are not actually updated, just going, it’s oscillating.  For example, adding something, subtracting something, adding something, subtracting something, then you understand that is kind of a local minima  or maximum you… you stuck with. So that is one measure of doing it. Second is, it takes inordinate time to learn, okay? Normally if it learns in two minutes or three minutes and it takes one hour sure that there is something wrong. What's the solution? There is no complicated solution in this problem. What you're supposed to do is, you just re-run that program. That's all. As I said, if you re-run that program, all W one IJs and W two IJs are picked up randomly. When they are picked up randomly, they represent a random node on that N dimensional space and a different starting point for us. And it's quite possible that using a different starting point, you won't indulge into that local minima or maximum problem. And you will reach practically it is found, that in most cases, you… you sometimes you require to re-run, but most cases you will reach there without much of an issue. You may ask the next question. What is the guarantee that we’ll get that weight vector? It’ll learn… learn everything every input, you provided all fifty images of employee and what's the guarantee that the program will eventually learn identify each employee correctly? 

Theoretically, there is no guarantee we cannot… the back-propagation algorithm that we are using does not guarantee anything here. It doesn't say it will surely find out I guarantee that. Okay? So, there is no guarantee as such, but as I said, practically in most cases it does. Okay? The errors coming at H one is… is depicted in the figure that is there in the handout as well as on the PPT. you can see that there… there are three layers of the multi-layer network. The XIs, the His and... and the OJs. Okay? You can see that H one connection of H one with O one to OL all of them, okay and you can see that W two one one, W two one two, W two one three and all of them are actually calculated. Now you multiply the errors, okay, that you get at O one, O two, O three with the respective weight and that error is calculated at H one. 

This figure clearly indicates how that is done. And this is just one example. The same way you calculate errors at H two, H three, H four and so on and once those errors are calculated, the weights are updated. We have already seen how the weights are updated. And now let us look at the algorithm in a single shot as I have already mentioned is very complicated algorithm on the face of it but otherwise it's not all that complicated. If you look at this, you will realize. Okay, first thing is to decide number of neurons at each layer. You will have to decide that. And how it is done, we have already seen a few times. You decide input based on the size of file. Output, based on number of classification classes that you would like to classify the inputs into and the hidden units of geometric mean. Sometimes the hidden units are taken little more than geometric mean, where the number of features are more. Remember the job of hidden unit is to identify features out of input. So if you believe that there are the features are more the number of hidden units are increased, if you believe that number of features are less depending on the problem that you're solving, they are reduced. Okay? So, as I said, this all empirical people have done a lot of work on it and done a lot of research on it. And the results contain a lot of guidelines for people like us who like to code. And now you randomly initialize both layer of weights between point one and minus point one or sometimes even minus point zero five and plus point zero five. Now why we are keeping this weight value as very less?

It’s because researchers have again found that if you start with very less value of weights network learns quite easily. But if you keep some weights large, the problem is that those weights will bully others into that direction. So network with not only misclassify, those bulky weights will drive a network to learn in something different than what we wanted to. So the good idea is to keep the… the random weights that we start with to a very low value which is indicated here. And that's going to be we begin with our epoch as one, so that is epoch as one. And now you pick up the first input. For that input obviously, all I values you just provide to XIs and you let the HI being calculated. You know how it is calculated. OJ are also calculated. Find errors.                                                  Okay? How you find errors? You will have to get correct value for output units. So they are called YJs, so, get YJs. Find delta two, the error at output unit. Find delta one, the error at the hidden unit. If this weight is to be learned, please understand if it is correctly identifying. For example, I want that output unit to have value one and it gets me point ninety eight and my tolerance level is point one so, it is fine. If it is anything beyond point nine, it is acceptable to me. So, this unit does not require to learn.  So, I will not do anything here. But if it is point six or point seven or point eight or point eighty five, I know there is a difference which I want to bridge. So, in that case this process is applied. Okay? The weight is updated, okay? So, that weight update process which also uses eta as well as alpha, as we have seen before. And once you do that, now first of all you decide that W two IJ and then W one IJ and then update the weight by old weight plus this delta okay and old weight plus alpha into  delta and so on so forth, which we have already seen. So, I'm not going to stress it further here. Now this is something to be done for a single input. Once this input is done, you’ll try the next input and the next and the next and so on till all inputs are done. 

When all inputs are done, the weights are updated, one e poch is said to be over so the epoch value is incremented by one and if all units have learned everything you stop if it is not, you start the with the next epoch okay. So you go back to the place and restart. Okay, so the algorithm have to restart from that place. Again take the first input, second input, third input, update weights, update weights, update weights and at the end, again it finds that, okay, there is a unit which is not learned and will again restart. So, it will continue till all units are learned. That means that the expected value and the value that you get the difference between them is less than the tolerance value. For all units if it is the case the neural network is said to have learned what we wanted it to. Now once that is done, what we do is we store this weight W one IJ is basically a matrix. W two IJ is also a matrix. So this matrix value is stored somewhere, why? Because whenever we are testing this neural network, we’ll provide this information now we are not going to change this weight. We just let it flow and we'll see what the output is. So, that is called testing now, the testing also you need an algorithm. So, how the algorithm the handout and the PPT contains that algorithm as well. The algorithm begins with simple. Okay, the same back propagation neural network setup is provided. But instead of providing random weight values, you just populate it by the weight matrix that we already have stored. Now you provide the first testing input let it flow and the output is generated, that output is recorded. 

Output is not… you don't flow the errors back you don't do anything. You just note the output. And it is quite possible that you test the input for twenty test cases and out of that eighteen you get the correct answer two you may not. That is perfectly acceptable, you… it happens and that is common also. It’s the same way with child when you provide child with some examples of A and some examples of B and so on so forth some time he mistakes I for H and H for I it is possible. So that is common that is like human. Okay? So, that is what is done usually the tolerance level or testing is much, much higher, okay. So, in most cases it is point five. So, if it is more than point five it is considered to be one less than point five it is considered to be zero. So tolerance level is high. Obviously, it has to be high because program has not seen this input.

How actually this learning process is doing it? What's the mathematical view of it? If you want to understand, you can assume that we only have a two-dimensional space. Remember, we need an n dimensional space if we are using N weights. There is a figure in the handout as well as the PPT which talks about a two-dimensional space. In a two-dimensional space, we have multiple regions defining a class. What we want to do is to have a… and we take a very simple case where there are only two types of inputs A and not A for example. And what we want is to have a line which separates them. So, that line will have some slope and a C value you know why is equal to MX plus C is the equation of line M and C are constants and they are decided by this weights that we provide. So, when we start with random weights… random weights, the line actually is drawn in a random way on… on that plane. So, when we continuously update that, basically you… you get a line which separates what we want. So A and not A can be separated if you have A B C. What we need is there are multiple classes, so we need multiple lines and for that we need multiple neurons. 

So, once you do that, once the lines are properly drawn, the figure actually talks about a case where there are one two three four, four lines which are drawn in a way that it can separate one two three four five different classes. So, if you get those lines right, it will be able to identify, okay? So, basically the learning process is moving of that line to its right position which… which can separate the regions which describe a class. This line is known as decision surface. And if in a two dimensional space, it’s going to be a line. In a three dimensional case, it’s going to be a plane and so on. It can be n dimensional plane you have an n minus one dimensional decision surface. And that decision surface the… the learning process is basically to start with a random decision surface and come to the right or correct decision surface. Move in a direction to get one decision surface. But then there is one more thing which we must understand that not always have one decision surface. There are potentially infinite number of decision surfaces. We need to just get one, okay? 

So in most cases we’ll get one and our problem is solved.  Finding out correct planes as I said is a process which begins with random values okay, and converges to the right set of weights. The next thing that we are going to look at in this particular module is called Hopfield networks we only would trace a point here that the same thing which was used for localized information storage you can use for distributed storage. For example, if you have eight units, you can use eight units two raised to eight information but here you can use them and there is an example shown in the handout as well as the PPT. A simple Hopfield network you can see that there are eight units and they are connected with each other using some weights. Now once you connect them using some weights, what do they do? In fact, every unit does something that we've already seen. Every unit calculates the input multiplied by weight. If the input is one, the weight matters. If the input is zero, obviously the multiplication is zero the weight doesn't matter. So, what does every unit do? Every unit will look at the summation. If the summation is positive, it’ll learn to become active that means one. Summation is negative, it’ll be zero and every unit if it’s connected to some other unit with positive value it says to be stimulus. It provides that stimulus for the other unit to remain on.

If it provided negative connectivity if the weight is negative, it inhibits that neuron, okay? So, here you can see that there is a connection between one the first unit and the fourth unit with value five. What does that mean? If the unit number one remains active the… there is it tries forces the fourth unit to be active with that weight five. It is also possible that a unit contains some negative some positive values. At that point of time the summation is done. Let us start and again it's quite interesting such a network will only have few stable states. For example, let us begin with this case where we initialize the first unit with one. The rest of the units are not touched. But you can see that it is connected with the third unit in a negative connection, the fourth unit with positive. So, if you set the first one to one, the third unit becomes zero and the fourth becomes one automatically because they are connected that way. 

You make the second unit turn on, you can see that the… the next unit the two more units, six and seven units will get zero and one because they're connected that way. So you just do that is the process is shown in the slide you just set a few values and you get the answer. And if you change them you set first two and the last one, you’ll get a different answer. In fact, there are a few different answers possible, but only few of them. In this case, I believe that there are three four possible answers. You start with anything you get either of them at the end. Now you may tell me that suppose if it gets five or six total possible values stored. Now, in the earlier case, I had two raised to eight and now I only get four, five. What’s the advantage of doing it? The advantage of doing it is that this… this mimic human capability of associative search. So, this for even incorrect inputs you will be able to get the right output. Okay, so that's… that's the power of Hopfield network. In fact, with Hopfield network a lot of other things which one can talk about. I won't be talking about them. One big problem which the this thing, Hopfield network can solve is, this travelling salesman problem. Okay, with that note… there is some information available about… this thing in our handout, and as well as a lot of other references which talks about that. With that note, I'd like to conclude this thing and just summarize everything that we have done in this module. We looked at how back propagation calculate the activation changes, the weights, updates itself, and get the right set of weights for every input to be classified properly. We also seen how Hopfield networks are used for associative search with that we’ll conclude. Thank you.


